---
title: "Fitting Exercise"
author: "Patrick Kaggwa"
date: "2024-02-29"
output: html_document
editor: 
  markdown: 
    wrap: sentence
---

# Data processing and exploration

# Loading needed packages.

```{r}
library(nlmixr2data)
library(readxl) #for loading Excel files
library(dplyr) #for data processing/cleaning
library(tidyr) #for data processing/cleaning
library(skimr) #for nice visualization of data 
library(here) #to set paths
library(readr)
library(ggplot2)
library(dplyr)
library(tidyr)
library(corrplot)
```

# Data loading

```{r}
# path to data
# note the use of the here() package and not absolute paths
# Defining the location of the CSV file
data_location <- here::here("fitting-exercise", "Mavoglurant_A2121_nmpk.csv")

# Reading the CSV file into a data frame
rawdata <- readr::read_csv(data_location)

# View the structure of the data
str(rawdata)

# View the first few rows of the data
head(rawdata)
```

# Plotting the outcome (DV)

A plot that shows a line for each individual, with DV on the y-axis and time on the x-axis.
Stratify by dose

```{r}
# Plot DV as a function of time, stratified by dose and using ID as a grouping factor
ggplot(rawdata, aes(x = TIME, y = DV, color = as.factor(DOSE), group = ID)) +
  geom_line() +
  labs(x = "Time", y = "Dependent Variable, Mavoglurant", color = "Dose") +
  facet_wrap(~ DOSE, scales = "free", ncol = 1) +
  ggtitle("Outcome Variable vs. Time Stratified by Dose") +
  theme_minimal()
```

> After formatting of the dataset, it still looks a bit strange.
> One thing you we notice is that there are some individuals that seem to have received the drug more than once, indicated by having both entries with OCC=1 and OCC=2.
> Since we are not sure what the difference is, we only keep one dataset for each individual.
> Therefore, remove all entries with OCC=2.

```{r}
# Keeping only observations with OCC = 1
rawdata <- rawdata[rawdata$OCC == 1, ]

```

> Now we see that each individual has an entry at time 0 that has DV=0 and some non-zero value for AMT.
> This is the dosing entry for everyone.
> All the other entries are the time-series values for the drug concentration.so instead we'll compute the total amount of drug for each individual by adding all the DV values.
> Note that this is a pretty bad idea, since some individuals might have more or less data points.
> The proper way to do this would be to do some form of integration to get the area under the curve, e.g. with a simple trapezoid rule, or to model the whole time-series with a function and then compute the AUC from that function.
> But to keep things simple, we'll go ahead - keeping in mind that in general, outside of a practice example, this is not a good idea.
>
> Creating a data frame that contains only the observations where TIME == 0.
> We shall use the appropriate join function to combine those two data frames.

```{r}
# Step 1: Exclude observations with TIME = 0
data_subset <- dplyr::filter(rawdata, TIME != 0)

# Step 2: Compute the sum of the DV variable for each individual
Y <- data_subset %>%
  group_by(ID) %>%
  summarize(Y = sum(DV))

# Step 3: Create a data frame containing only the observations where TIME == 0
data_time_0 <- dplyr::filter(rawdata, TIME == 0)

# Step 4: Combine the two data frames using inner_join
final_data <- dplyr::inner_join(Y, data_time_0, by = "ID")

# View the final data frame
head(final_data)
```

Finally, we'll do a bit more cleaning.
At this point, we don't need most of these indicator variables anymore (e.g., OCC or EVID).
We also want to convert RACE and SEX to factor variables.And we shall only these variables: Y,DOSE,AGE,SEX,RACE,WT,HT

```{r}
# Convert RACE and SEX to factor variables
final_data$RACE <- as.factor(final_data$RACE)
final_data$SEX <- as.factor(final_data$SEX)

# Select only the necessary variables
final_data <- final_data %>%
  select(Y, DOSE, AGE, SEX, RACE, WT, HT)

# View the cleaned-up data frame
head(final_data)

```

As part of the exploratory process above.
Do a few more here, once the data is clean.
We shall make some useful summary tables.
We shall show some scatter plot, box plot, histogram and pair/correlation plot between the main outcome of interest (total drug, Y) and other predictors.
Plot the distributions of your variables to make sure they all make sense.

## Visualization

```{r}
# Summary table
summary_table <- final_data %>%
  group_by(RACE, SEX) %>%
  summarize(
    Mean_Y = mean(Y),
    Median_Y = median(Y),
    Min_Y = min(Y),
    Max_Y = max(Y)
  )
print(summary_table)
```

```{r}
# Scatterplot between outcome(Y) and AGE
ggplot(final_data, aes(x = AGE, y = Y)) +
  geom_point() +
  labs(x = "Age", y = "Total Drug (Y)", title = "Scatterplot: Total Drug vs Age")
```

According to the scatter I don't see any meaningful pattern.

```{r}
# Boxplot between Y and DOSE
ggplot(final_data, aes(x = as.factor(DOSE), y = Y)) +
  geom_boxplot() +
  labs(x = "Dose", y = "Total Drug (Y)", title = "Boxplot: Total Drug vs Dose")

```

```{r}
ggplot(final_data, aes(x = Y)) +
  geom_histogram(bins = 20, fill = "blue", color = "black") +
  labs(x = "Total drug", y = "Frequency", title = "Distribution of Total drug")
```

Looking at the bar graph, the total drug looks a little skewed to the left.

Now we shall do a correlation plot to visually inspect the relationships between variables and identify patterns or correlations.

```{r}
# Pair/correlation plot
correlation_matrix <- cor(final_data[, c("Y", "DOSE", "AGE", "WT", "HT")])
corrplot(correlation_matrix, method = "circle")
```

According to the plot there is a high correlation between Total drug(Y) and Dose.

## Model fitting

1.  We shall fit a linear model to the continuous outcome (Y) using the main predictor of interest, which we'll assume here to be DOSE and 2. Fit a linear model to the continuous outcome (Y) using all predictors. For both models, compute RMSE and R-squared and print them out.

```{r}
# Load necessary packages
#install.packages("tidymodels")
library(tidymodels)
```

```{r}
# Fit a linear model using the main predictor of interest (DOSE)
linear_model_dose <- lm(Y ~ DOSE, data = final_data)
linear_model_dose
```

```{r}
# Fit a linear model using all predictors
linear_model_all <- lm(Y ~ DOSE + AGE + SEX + RACE, data = final_data)
linear_model_all
```

```{r}
# Function to compute RMSE
compute_rmse <- function(model, actual_values) {
  predicted_values <- predict(model)
  rmse <- sqrt(mean((predicted_values - actual_values)^2))
  return(rmse)
}

```

```{r}
# Function to compute R-squared
compute_r_squared <- function(model, actual_values) {
  predicted_values <- predict(model)
  r_squared <- summary(model)$r.squared
  return(r_squared)
}

```

```{r}
# Computing RMSE and R-squared for the model with main predictor (DOSE)
rmse_dose <- compute_rmse(linear_model_dose, final_data$Y)
r_squared_dose <- compute_r_squared(linear_model_dose, final_data$Y)

```

```{r}
# Compute RMSE and R-squared for the model with all predictors
rmse_all <- compute_rmse(linear_model_all, final_data$Y)
r_squared_all <- compute_r_squared(linear_model_all, final_data$Y)
```

```{r}
# Print RMSE and R-squared for both models
cat("Linear model with main predictor (DOSE):\n")
cat("RMSE:", rmse_dose, "\n")
cat("R-squared:", r_squared_dose, "\n\n")
cat("Linear model with all predictors:\n")
cat("RMSE:", rmse_all, "\n")
cat("R-squared:", r_squared_all, "\n")

```

### Linear model with main predictor (DOSE):

RMSE: 666.4618 R-squared: 0.5156446 The linear model with DOSE as the main predictor yielded an RMSE of 666.4618, indicating that, on average, the model's predictions deviated by approximately 666.4618 units from the actual values.
The R-squared value of 0.5156446 suggests that DOSE explains approximately 51.56% of the variance in the outcome variable (Y).
This indicates a moderate level of explanatory power for DOSE alone in predicting the outcome variable.

### Linear model with all predictors:

RMSE: 656.1714 R-squared: 0.5304863 The linear model with all predictors resulted in a slightly lower RMSE of 656.1714 compared to the model with DOSE alone.
This suggests that including additional predictors slightly improved the model's predictive accuracy.
The R-squared value of 0.5304863 indicates that the model with all predictors explains approximately 53.05% of the variance in the outcome variable (Y), representing a slight improvement in explanatory power compared to the model with DOSE alone.

#### Comments and thoughts:

While both models show some level of predictive ability, there is room for improvement in terms of predictive accuracy and explanatory power.
Further refinement of the models and consideration of additional predictors or model specifications may be necessary to develop more accurate and reliable predictive models.

Now we shall SEX as the outcome of interest (that doesn't make too much scientific sense, but we want to practice fitting both continuous and categorical outcomes).

```{r}
# Fit a logistic model using the main predictor of interest (DOSE)
logistic_model_dose <- glm(SEX ~ DOSE, data = final_data, family = binomial)

```

```{r}
# Fit a logistic model using all predictors
logistic_model_all <- glm(SEX ~ ., data = final_data, family = binomial)

```

```{r}
# Function to compute accuracy
compute_accuracy <- function(model, actual_values) {
  predicted_values <- ifelse(predict(model, type = "response") >= 0.5, 1, 0)
  accuracy <- mean(predicted_values == actual_values)
  return(accuracy)
}
```

```{r}
# Function to compute ROC-AUC
compute_roc_auc <- function(model, actual_values) {
  library(pROC)
  predicted_values <- predict(model, type = "response")
  roc_auc <- auc(roc(actual_values, predicted_values))
  return(roc_auc)
}
```

```{r}
# Computing the accuracy and ROC-AUC for the model with main predictor (DOSE)
accuracy_dose <- compute_accuracy(logistic_model_dose, final_data$SEX)
roc_auc_dose <- compute_roc_auc(logistic_model_dose, final_data$SEX)
```

```{r}
# Compute accuracy and ROC-AUC for the model with all predictors
accuracy_all <- compute_accuracy(logistic_model_all, final_data$SEX)
roc_auc_all <- compute_roc_auc(logistic_model_all, final_data$SEX)

```

```{r}
# Print accuracy and ROC-AUC for both models
cat("Logistic model with main predictor (DOSE):\n")
cat("Accuracy:", accuracy_dose, "\n")
cat("ROC-AUC:", roc_auc_dose, "\n\n")

cat("Logistic model with all predictors:\n")
cat("Accuracy:", accuracy_all, "\n")
cat("ROC-AUC:", roc_auc_all, "\n")
```

### Interpreting the results

Logistic model with main predictor (DOSE):

Accuracy: 0 ROC-AUC: 0.5919 The logistic model with DOSE as the main predictor yielded an accuracy of 0, indicating that the model did not correctly classify any observations.
The ROC-AUC score of 0.5919 suggests that the model's ability to discriminate between the two classes of (SEX) is slightly better than random chance, but it is still relatively low.

Logistic model with all predictors:

Accuracy: 0.025 ROC-AUC: 0.9796 The logistic model with all predictors resulted in a slightly improved accuracy of 0.025, indicating that the model correctly classified approximately 2.5% of the observations.
The ROC-AUC score of 0.9796 suggests that this model has excellent discriminative power, with a high probability of correctly ranking a randomly chosen positive instance higher than a randomly chosen negative one.

#### Comments and thoughts:

While the logistic model with all predictors shows promise in predicting SEX, further refinement and exploration of the data are necessary to develop a more accurate and reliable model.
Additionally, careful consideration of the underlying relationships between predictors and the outcome variable is crucial for interpreting and improving model performance.

```{r}
#install.packages("kknn")
library(kknn)
# Fit a KNN model to the continuous outcome (Y)
knn_model_continuous <- nearest_neighbor(weight_func = "rectangular", neighbors = tune()) %>%
  set_engine("kknn") %>%
  set_mode("regression") %>%
  fit(Y ~ ., data = final_data)
```

```{r}
# Fit a KNN model to the categorical outcome (SEX)
knn_model_categorical <- nearest_neighbor(weight_func = "rectangular", neighbors = tune()) %>%
  set_engine("kknn") %>%
  set_mode("classification") %>%
  fit(SEX ~ ., data = final_data)
```

```{r}
# Print the models
knn_model_continuous
knn_model_categorical
```

### KNN Model for Continuous Outcome (Y):

**Interpretation**

Type of response variable: Continuous Minimal mean absolute error: 777.3232 Minimal mean squared error: 910968.3 Best kernel: Rectangular Best k: 115 Interpretation: For the model predicting the continuous outcome (Y), the minimal mean absolute error (MAE) is 777.3232, indicating the average absolute difference between the predicted and actual values.
The minimal mean squared error (MSE) is 910968.3, representing the average squared difference between the predicted and actual values.
The best kernel for this model is rectangular, and the optimal value of k is 115.

### KNN Model for Categorical Outcome (SEX):

Type of response variable: Nominal Minimal misclassification: 0.1333333 Best kernel: Rectangular Best k: 115 Interpretation: For the model predicting the categorical outcome (SEX), the minimal misclassification rate is 0.1333333, indicating the proportion of incorrectly classified instances.
The best kernel for this model is rectangular, and the optimal value of k is 115.
A misclassification rate of 0.1333333 suggests that approximately 13.33% of the instances are misclassified by the model.
